# -*- coding: utf-8 -*-
"""MyCnn

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y-rGPynxCs17JnJRkPfo5jTl733ijY68
"""

# подключаем личный диск к блокноту
from google.colab import drive
drive.mount('/content/drive')

import os 
# назначем корневые пути до исходных данных
path="/content/drive/MyDrive/source/DICOM"
inPath=os.listdir("/content/drive/MyDrive/source/DICOM")
inPath

pneum_path=path+"/Pneumonia/Пневмония"
tub_path=path+"/Tuberculosis/Туберкулез"
can_path=path+"/Cancer/0"
print(pneum_path,
tub_path,
can_path)

arrPneumPath=os.listdir(pneum_path)
arrTubPath=os.listdir(tub_path)
arrCanPath=os.listdir(can_path)

!pip install pydicom
!pip install opencv-python
!pip install Pillow
!pip install numpy scipy scikit-learn

!pip install pandas

import pandas as pd
df = pd.DataFrame(preCsv) # загружаем данные КТ снимоков в pandas
df.to_csv('file.csv', index=False, header=True) # сохраняем в файл

# назначем названия колонок и раскрываем содержимое датафрейма:
df.columns = ['Type', 'img_name', 'path_to_img']
df

# функция форматирование путей для pandas
def spliting(arr):
    splitArray=[]
    for i in range(0,len(arr)):
        splitArray.append(arr[i].split('/'))
    return splitArray
spliter=spliting(arrPneum)+spliting(arrTub)+spliting(arrCan)

size=[]
# функция вычисления количества больных каждого типа болезни
def sizeCheked(arrPneum):
    pixel_array_numpy=[]
    for i in range(0, len(arrPneum)):
        try:
            image_path = arrPneum[i]
            ds = dicom.dcmread(image_path)
            pixel_array_numpy.append(ds.pixel_array)
        except FileNotFoundError:
            print(i, ": none")
    for i in range(0, len(pixel_array_numpy)):
        for j in range(0, len(pixel_array_numpy[i])):
            if(pixel_array_numpy[i][j].size!=512):
                print(pixel_array_numpy[i][j].size)

# импортируем необходимые библиотеки
import pydicom as dicom
import cv2
from PIL import Image
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
import numpy as np

# функция вычисления путей до конктреного слоя кт
def addPath(path, arrPath):
    arr=[]
    for i in range(0, len(arrPath)):
        inDirectory=os.listdir(path+"/"+arrPath[i])
        new_path=path+"/"+arrPath[i]
        for j in range(0, len(inDirectory)):
            inPostDirectory=os.listdir(new_path+"/"+inDirectory[j]+"/")
            for k in range(0, len(inPostDirectory)):
                end_pneum_path=new_path+"/"+inDirectory[j]+"/"+inPostDirectory[k]
                inLastDir=os.listdir(end_pneum_path)
                for m in range(0, len(inLastDir)):
                    endDir=end_pneum_path+"/"+inLastDir[m]
                    arr.append(endDir)
    return arr
arrPneum=addPath(pneum_path, arrPneumPath)
arrTub=addPath(tub_path, arrTubPath)
arrCan=addPath(can_path, arrCanPath)

# функция форматирование путей для pandas
def spliting(arr):
    splitArray=[]
    for i in range(0,len(arr)):
        splitArray.append(arr[i].split('/'))
    return splitArray
spliter=spliting(arrPneum)+spliting(arrTub)+spliting(arrCan)

# созздаепм верный формат путей до КТ снимков для загрузки их в pandas
preCsv=[]
for i in range(0,len(spliter)):
    preCsv.append([spliter[i][6], spliter[i][10], "/".join(spliter[i])])

!pip install pandas

import pandas as pd
df = pd.DataFrame(preCsv) # загружаем данные КТ снимоков в pandas
df.to_csv('file.csv', index=False, header=True) # сохраняем в файл

# назначем названия колонок и раскрываем содержимое датафрейма:
df.columns = ['Type', 'img_name', 'path_to_img']
df

import numpy as np
# функция преобразования в хаумсфилдские юниты снимка КТ
def get_pixels_hu(scans):
    image = np.stack([scans.pixel_array])#np.stack([s.pixel_array for s in scans])
    # Convert to int16 (from sometimes int16), 
    # возможно, так как значения всегда должны быть достаточно низкими (<32k)
    image = image.astype(np.int16)

    # Установит значение пикселов вне области сканирования равным 1
    # intercept обычно составляет -1024, так что воздух составляет примерно 0
    image[image == -2000] = 0
    
    # Convert to Hounsfield units (HU)
    intercept = scans.RescaleIntercept
    slope = scans.RescaleSlope
    
    if slope != 1:
        image = slope * image.astype(np.float64)
        image = image.astype(np.int16)
        
    image += np.int16(intercept)
    
    return np.array(image, dtype=np.int16)

from skimage.transform import resize

# Обертачная функция для финкции преобразования в хаумсфилдские юниты снимка КТ
def get_pixel_uid(x):
    try:
        dcm_x=dicom.dcmread(x, force=True)
        #dcm_x.file_meta.TransferSyntaxUID = dicom.uid.ImplicitVRLittleEndian
    
        return get_pixels_hu(dcm_x).flatten()
    except AttributeError:
        return None

import tensorflow as tf

# преорбразуем каждый DICOM снимок в хаумсфилдские юниты
with tf.device('/GPU:0'):
        df["img"]=df["path_to_img"].apply(lambda x: get_pixel_uid(x))

#Standardize the pixel values
from sklearn.cluster import KMeans
from skimage import morphology
from skimage import measure


def make_lungmask(img, display=False):
    row_size= img.shape[0]
    col_size = img.shape[1]
    
    mean = np.mean(img)
    std = np.std(img)
    
    img = img-mean
    img = img/std
    # Найти среднее значение пикселя рядом с легкими
    # для перенормировки размытых изображений
    middle = img[int(col_size/5):int(col_size/5*4),int(row_size/5):int(row_size/5*4)] 
    mean = np.mean(middle)  
    max = np.max(img)
    min = np.min(img)
    # 
    # 
    img[img==max]=mean
    img[img==min]=mean
    #
    # Использование Kmeans для разделения переднего плана (мягкие ткани / кости) и фона (легкие / воздух)
    #
    kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))
    #Получаю центр каждого кластера
    centers = sorted(kmeans.cluster_centers_.flatten())
    
    threshold = np.mean(centers)
    
    thresh_img = np.where(img<threshold,1.0,0.0)  # пороговое значение изображения

    # Сначала удаляются более мелкие элементы, затем расширяются, чтобы включить некоторые пиксели, окружающие легкое. 
    # нельзя случайно задеть легкое.

    eroded = morphology.erosion(thresh_img,np.ones([3,3]))
    dilation = morphology.dilation(eroded,np.ones([8,8]))
    #Получение связанной области изображения
    labels = measure.label(dilation) # Разные части отображаются разными цветами
    
    #Получение уникальных областей
    label_vals = np.unique(labels)
    
    regions = measure.regionprops(labels)
   
    good_labels = []
    for prop in regions:
        B = prop.bbox
        if B[2]-B[0]<row_size/10*9 and B[3]-B[1]<col_size/10*9 and B[0]>row_size/5 and B[2]<col_size/5*4:
            good_labels.append(prop.label)
    mask = np.ndarray([row_size,col_size],dtype=np.int8)
    mask[:] = 0

    #
    #  После того, как останутся только легкие, делаем еще одну операцию, чтобы заполнить и удалить легочную маску
    for N in good_labels:
        mask = mask + np.where(labels==N,1,0)
    print("mask: ",mask)
    mask = morphology.dilation(mask,np.ones([10,10])) # one last dilation

    # if (display):
    #     fig, ax = plt.subplots(3, 2, figsize=[12, 12])
    #     ax[0, 0].set_title("Original")
    #     ax[0, 0].imshow(img, cmap='gray')
    #     ax[0, 0].axis('off')
    #     ax[0, 1].set_title("Threshold")
    #     ax[0, 1].imshow(thresh_img, cmap='gray')
    #     ax[0, 1].axis('off')
    #     ax[1, 0].set_title("After Erosion and Dilation")
    #     ax[1, 0].imshow(dilation, cmap='gray')
    #     ax[1, 0].axis('off')
    #     ax[1, 1].set_title("Color Labels")
    #     ax[1, 1].imshow(labels, cmap='plasma')
    #     ax[1, 1].axis('off')
    #     ax[2, 0].set_title("Final Mask")
    #     ax[2, 0].imshow(mask, cmap='gray')
    #     ax[2, 0].axis('off')
    #     ax[2, 1].set_title("Apply Mask on Original")
    #     ax[2, 1].imshow(mask*img, cmap='gray')
    #     ax[2, 1].axis('off')
        
    #     plt.show()
    return mask*img
def resample(image, scan, new_spacing=[1,1,1]):
    # Determine current pixel spacing
    spacing = map(float, ([scan[0].SliceThickness] + list(scan[0].PixelSpacing)))
    spacing = np.array(list(spacing))

    resize_factor = spacing / new_spacing
    new_real_shape = image.shape * resize_factor
    new_shape = np.round(new_real_shape)
    real_resize_factor = new_shape / image.shape
    new_spacing = spacing / real_resize_factor
    
    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor)
    
    return image, new_spacing

def aply_mask(img):
    try:
        return  resize(make_lungmask(img.reshape(512,512)), (112,112))
    except:
        return None
df["mask"]=df["img"].apply(lambda x:aply_mask(x))

dx = df.sample(frac=1).reset_index(drop=True)

dx.isnull().sum()

dx.isnull().sum()
dx=dx[dx['img'].notna()]
dx.isnull().sum()

Xc=np.concatenate((Xc[0:107],Xc[108:len(Xc)]))

Yc=np.concatenate((Yc[0:107],Yc[108:len(Yc)]))

new_X=[]
for i in range(0,len(Xc)):
    new_X.append(Xc[i].reshape((512,512,1)))

new_X=np.array(new_X)

BATCH_SIZE = 150
EPOCHS = 200



Xc = dx['img']
Yc = dx['Type']
# encode class values as integers
encoder = LabelEncoder()
encoder.fit(Yc)

# конфигурация обучения
BATCH_SIZE = 150 
EPOCHS = 200

#определение модели
def my_cnn_model():
    cnn_model = tf.keras.Sequential([

       tf.keras.layers.Conv2D(filters=32, kernel_size=(9,9), activation=tf.nn.relu,padding = "same"),
         tf.keras.layers.MaxPool2D(pool_size=(2,2)),
        tf.keras.layers.BatchNormalization(),
        
        
         tf.keras.layers.Conv2D(filters=64, kernel_size=(11,11), activation=tf.nn.relu,padding = "same"),
         tf.keras.layers.BatchNormalization(),
          
        
         tf.keras.layers.Conv2D(filters=32, kernel_size=(15,15), activation=tf.nn.relu,padding = "same"),
        tf.keras.layers.MaxPool2D(pool_size=(2,2)),
         tf.keras.layers.BatchNormalization(),

          tf.keras.layers.Conv2D(filters=64, kernel_size=(17,17), activation=tf.nn.relu,padding = "same"),
         tf.keras.layers.BatchNormalization(),

          tf.keras.layers.Conv2D(filters=32, kernel_size=(23,23), activation=tf.nn.relu,padding = "same"),
          tf.keras.layers.MaxPool2D(pool_size=(2,2)),
         tf.keras.layers.BatchNormalization(),

          tf.keras.layers.Conv2D(filters=64, kernel_size=(27,27), activation=tf.nn.relu,padding = "same"),
         tf.keras.layers.BatchNormalization(),

         tf.keras.layers.Conv2D(filters=32, kernel_size=(31,31), activation=tf.nn.relu,padding = "same"),
          tf.keras.layers.MaxPool2D(pool_size=(2,2)),
         tf.keras.layers.BatchNormalization(),

        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(512, activation=tf.nn.relu),
        tf.keras.layers.Dense(128, activation=tf.nn.relu),

        tf.keras.layers.Dense(64, activation=tf.nn.relu),

        tf.keras.layers.Dense(3, activation=tf.nn.softmax)
        
    ])
    
    return cnn_model

cnn_model = my_cnn_model()
callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=90)

cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
with tf.device('/GPU:0'):
    m = cnn_model.fit(new_X[0:4000], dummy_y[0:4000], batch_size=BATCH_SIZE,validation_data=(new_X[4000:5934], dummy_y[4000:5934]), epochs=EPOCHS,callbacks=[callback])
r = cnn_model.evaluate(new_X[4000:5934], dummy_y[4000:5934], verbose=0)
y_pred = cnn_model.predict(new_X[4000:5934], batch_size=64, verbose=0)
print('Test accuracy:', r[0])
print('Test f1_score:', r[1])